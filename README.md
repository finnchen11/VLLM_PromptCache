# ğŸ§  vLLM System Prompt Cache â€”â€” ç³»ç»Ÿæç¤ºè¯ç¼“å­˜ä¼˜åŒ–æ¨¡å—

> âš¡ åŸºäº vLLM çš„ç³»ç»Ÿæç¤ºè¯ï¼ˆSystem Promptï¼‰ç¼“å­˜ä¸å¤ç”¨æœºåˆ¶ï¼Œæå‡å¤šè½®å¯¹è¯åœºæ™¯ä¸‹çš„æ¨ç†æ€§èƒ½ã€‚

---

## ğŸ“Œ é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®åŸºäº [vLLM](https://github.com/vllm-project/vLLM) è¿›è¡Œæ‰©å±•ï¼Œå®ç°äº† **ç³»ç»Ÿæç¤ºè¯æ°¸ä¸é‡Šæ”¾ + ç¼“å­˜å¤ç”¨æœºåˆ¶**ï¼Œç‰¹åˆ«é€‚ç”¨äºä»¥ä¸‹åœºæ™¯ï¼š

- å¤šç”¨æˆ·å…±äº«ç›¸åŒç³»ç»Ÿæç¤ºå¹¶ä¸”ç³»ç»Ÿæç¤ºè¯é•¿åº¦ç‰¹åˆ«å¤§ï¼Œé¢„å¡«å……é˜¶æ®µè€—æ—¶å¤š
- åŸç”ŸVllmçš„blockç®¡ç†ç­–ç•¥ï¼ˆLURæœºåˆ¶ï¼‰åœ¨æ²¡æœ‰è¯·æ±‚æ—¶é‡Šæ”¾cacheï¼Œæ–°æ¥çš„è¯·æ±‚åˆä¼šé‡æ–°è®¡ç®—
- é«˜é¢‘è¯·æ±‚ä¸­é‡å¤ä½¿ç”¨ç›¸åŒ system prompt
- éœ€è¦èŠ‚çœæ˜¾å­˜å¹¶æé«˜ååé‡çš„éƒ¨ç½²ç¯å¢ƒ

é€šè¿‡è¯¥æ¨¡å—ï¼Œä½ å¯ä»¥ï¼š

âœ… **é¿å…é‡å¤åˆ†é… KV Cache**  
âœ… **æ˜¾è‘—å‡å°‘å†…å­˜å ç”¨ä¸æ¨ç†å»¶è¿Ÿ**  
âœ… **æ— ç¼å…¼å®¹ OpenAI API æ¥å£**

---

## ğŸ” åŠŸèƒ½äº®ç‚¹

| åŠŸèƒ½ | æè¿° |
|------|------|
| âœ… ç³»ç»Ÿæç¤ºè¯ç¼“å­˜ | è‡ªåŠ¨è¯†åˆ« `role: "system"` æ¶ˆæ¯ï¼Œå¹¶ç¼“å­˜å…¶ KV Cache |
| âœ… ç¼“å­˜æ°¸ä¸é‡Šæ”¾ | æ ‡è®°ä¸º `is_system_prompt` çš„åºåˆ—ä¸ä¼šè¢«é‡Šæ”¾ |
| âœ… ç¼“å­˜å—å¤åˆ¶å¤ç”¨ | æ”¯æŒåœ¨å¤šä¸ªè¯·æ±‚ä¹‹é—´é«˜æ•ˆå¤ç”¨ç¼“å­˜å— |
| âœ… å…¼å®¹ OpenAI SDK | å¯é€šè¿‡ `openai.ChatCompletion.create()` ç›´æ¥è°ƒç”¨ |
| âœ… æ€§èƒ½ä¼˜åŒ– | å‡å°‘å†…å­˜åˆ†é…å¼€é”€ï¼Œæå‡å¹¶å‘ååèƒ½åŠ› |

---

## ğŸ› ï¸ å®‰è£…ä¸éƒ¨ç½²

### 1. å…‹éš†é¡¹ç›®

```bash
git clone https://github.com/finnchen11/VLLM_PromptCache.git
cd VLLM_PromptCache
```

### 2. å®‰è£…ä¾èµ–

å»ºè®®ä½¿ç”¨ Python 3.8+ å’Œ PyTorch 2.0+

```bash
pip install -e .
```

æˆ–è€…ä»åŸå§‹ vLLM å®‰è£…åæ‰‹åŠ¨æ›¿æ¢æ–‡ä»¶ã€‚

### 3. å¯åŠ¨æœåŠ¡

```bash
python -m vllm.entrypoints.openai.api_server --host 0.0.0.0 --port 8000 --model your_model_name
```

---

## ğŸ“¦ ä½¿ç”¨æ–¹å¼

### 1. ä½¿ç”¨ curl è°ƒç”¨

```bash
curl -X POST http://localhost:8000/v1/chat/completions \
    -H "Content-Type: application/json" \
    -d '{
        "model": "llama3",
        "messages": [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "è®²ä¸ªç¬‘è¯"}
        ]
    }'
```

### 2. ä½¿ç”¨ OpenAI SDK

```python
import openai

openai.api_base = "http://localhost:8000/v1"
openai.api_key = "EMPTY"

completion = openai.ChatCompletion.create(
    model="llama3",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "è®²ä¸ªç¬‘è¯"},
    ]
)
print(completion.choices[0].message.content)
```

---

## ğŸ§© æ ¸å¿ƒä¿®æ”¹è¯´æ˜

ä»¥ä¸‹æ˜¯é¡¹ç›®ä¸­ä¸»è¦ä¿®æ”¹æˆ–æ–°å¢çš„æ–‡ä»¶åŠåŠŸèƒ½ï¼š

| æ–‡ä»¶ | ä¿®æ”¹å†…å®¹ |
|------|----------|
| `sequence.py` | æ–°å¢ `is_system_prompt` å­—æ®µç”¨äºæ ‡è®°ç³»ç»Ÿæç¤ºè¯ |
| `worker/cache_engine.py` | å®ç° `free()` ä¸­åˆ¤æ–­æ˜¯å¦ä¸ºç³»ç»Ÿæç¤ºè¯ï¼Œä¸é‡Šæ”¾ç¼“å­˜ï¼›æ·»åŠ  `copy()` æ–¹æ³•æ”¯æŒç¼“å­˜å—å¤ç”¨ |
| `engine/llm_engine.py` | æ·»åŠ  `add_system_prompt()` æ–¹æ³•ï¼Œå®ç°ç³»ç»Ÿæç¤ºè¯ç¼“å­˜æ± ç®¡ç† |
| `entrypoints/openai/api_server.py` | åœ¨ `/v1/chat/completions` æ¥å£ä¸­æå– system æç¤ºè¯å¹¶è°ƒç”¨ç¼“å­˜æœºåˆ¶ |
| `vllm/worker/worker.py` | ä¿®æ”¹ `_init_cache_engine()` æ–¹æ³•ï¼Œç¡®ä¿å¤šä¸ª CacheEngine å…±äº«åŒä¸€ä¸ª block_manager |

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| åœºæ™¯ | åŸå§‹ vLLM | åŠ å…¥ç³»ç»Ÿæç¤ºè¯ç¼“å­˜å |
|------|------------|---------------------|
| å†…å­˜å ç”¨ | é«˜ | æ˜¾è‘—é™ä½ |
| å•æ¬¡æ¨ç†æ—¶é—´ | é«˜ï¼ˆé¦–æ¬¡ç¼“å­˜æœªå‘½ä¸­ï¼‰ | å¿«é€Ÿï¼ˆåç»­å‘½ä¸­ç¼“å­˜ï¼‰ |
| å¹¶å‘ååé‡ | ä¸€èˆ¬ | æ˜æ˜¾æå‡ |

---

## ğŸ”„ ç³»ç»Ÿæç¤ºè¯ç¼“å­˜æœºåˆ¶å·¥ä½œæµç¨‹

```
ç”¨æˆ·è¯·æ±‚
    â†“
[vLLM API Server] api_server.py
    â†’ æå–æ¶ˆæ¯ä¸­çš„ "role": "system" å†…å®¹
    â†’ è°ƒç”¨ engine.add_system_prompt(prompt)

    â†“
[LLM Engine] llm_engine.py
    â†’ æ£€æŸ¥ system_prompt_cache æ˜¯å¦å·²ç¼“å­˜ç›¸åŒæç¤ºè¯
    â†’ è‹¥å­˜åœ¨åˆ™ç›´æ¥å¤ç”¨ï¼Œè‹¥ä¸å­˜åœ¨åˆ™åˆ›å»ºæ–° Sequence å¹¶æ ‡è®°ä¸º is_system_prompt=True
    â†’ é€šè¿‡ CacheEngine åˆ†é… KV Cache å—

    â†“
[Cache Engine] cache_engine.py
    â†’ åœ¨ allocate() ä¸­ä¸ºç³»ç»Ÿæç¤ºè¯åˆ†é…ç¼“å­˜å—
    â†’ æ‰€æœ‰åç»­è°ƒç”¨ free(seq) æ—¶ï¼Œæ£€æŸ¥ seq.is_system_prompt
    â†’ è‹¥ä¸º Trueï¼Œåˆ™è·³è¿‡é‡Šæ”¾ï¼Œå®ç°â€œæ°¸ä¸é‡Šæ”¾â€

    â†“
[Worker] worker.py
    â†’ æ‰€æœ‰ CacheEngine å®ä¾‹å…±äº«åŒä¸€ä¸ª block_manager
    â†’ ä¿è¯ç¼“å­˜å—åœ¨ä¸åŒ pipeline stage é—´ä¸€è‡´ä¸”å¯å¤ç”¨

    â†“
[ç¼“å­˜å¤ç”¨]
    â†’ å½“å†æ¬¡å‡ºç°ç›¸åŒ system prompt æ—¶
    â†’ ç›´æ¥å¤ç”¨å·²ç¼“å­˜çš„ Sequence å’Œå…¶ KV Cache å—
    â†’ é¿å…é‡å¤è®¡ç®—å’Œå†…å­˜åˆ†é…ï¼Œæ˜¾è‘—æå‡æ€§èƒ½

    â†“
è¿”å›ç»“æœç»™ç”¨æˆ· âœ…
```

---

